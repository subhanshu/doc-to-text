# Document Text Extractor Service

A production-ready FastAPI service for extracting text from PDF and Word (.docx) documents. This service is optimized for Railway deployment and can handle multiple files concurrently.

## Features

- **Multi-format support**: PDF and Word (.docx) files
- **Concurrent processing**: Uses ProcessPoolExecutor for CPU-bound extraction tasks
- **Progress tracking**: Real-time progress monitoring for bulk operations
- **Background processing**: Asynchronous file processing with status updates
- **Production ready**: Optimized for Railway deployment with proper resource management
- **Robust error handling**: Comprehensive error handling and timeouts
- **File size limits**: Configurable file size and count limits
- **Health checks**: Built-in health endpoint for monitoring

## API Endpoints

### API Information
```
GET /
```
Returns basic information about the API, supported formats, and available endpoints.

### Health Check
```
GET /health
```
Returns service status and configuration.

### Text Extraction
```
POST /extract
```
Extract text from uploaded files. Accepts multiple files in a single request and returns all results at once.

### Progress Tracking Extraction
```
POST /extract-progress
```
Extract text from uploaded files with real-time progress tracking. Returns a session ID for monitoring progress.

### Progress Monitoring
```
GET /progress/{session_id}
```
Get real-time progress for a bulk processing session.

### Session Cleanup
```
DELETE /progress/{session_id}
```
Clean up progress data for a completed session.

### API Documentation
- **Interactive Docs (Swagger UI)**: `/docs`
- **ReDoc Documentation**: `/redoc`
- **OpenAPI Schema**: `/openapi.json`

**Request**: Multipart form data with files
**Response**:
```json
{
  "results": [
    {
      "filename": "document.pdf",
      "text": "Extracted text content..."
    }
  ],
  "errors": [
    {
      "filename": "corrupted.pdf",
      "error": "Error message"
    }
  ]
}
```

## Configuration

The service uses environment variables with the `EXTRACT_` prefix:

- `EXTRACT_MAX_FILE_SIZE_BYTES`: Maximum file size (default: 20MB)
- `EXTRACT_MAX_TOTAL_FILES`: Maximum files per request (default: 8)
- `EXTRACT_PROCESS_POOL_WORKERS`: Number of worker processes (default: CPU cores - 1)
- `EXTRACT_MAX_CONCURRENT_REQUESTS`: Maximum concurrent requests (default: 3)
- `EXTRACT_PER_FILE_TIMEOUT`: Per-file extraction timeout in seconds (default: 30)
- `EXTRACT_REQUEST_TIMEOUT`: Overall request timeout in seconds (default: 120)

## Railway Deployment

1. **Connect your GitHub repository** to Railway
2. **Deploy automatically** - Railway will detect the Python project and use the Procfile
3. **Set environment variables** if needed (optional, defaults work well)
4. **Access your service** at the provided Railway URL

### Railway Configuration

The service includes:
- `Procfile`: Defines the web process command
- `railway.json`: Railway-specific configuration with health checks
- `requirements.txt`: Python dependencies

## Local Development

1. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Run the service**:
   ```bash
   uvicorn main:app --host 0.0.0.0 --port 8080 --workers 1
   ```

3. **Test the service**:
   ```bash
   curl -X POST "http://localhost:8080/extract" \
        -H "Content-Type: multipart/form-data" \
        -F "files=@document.pdf"
   ```

## Production Notes

- The service is optimized for a 4-core, 8GB VM
- Uses 3 Gunicorn workers with Uvicorn worker class
- ProcessPoolExecutor handles CPU-bound extraction tasks
- Semaphore limits concurrent requests to prevent resource exhaustion
- Automatic cleanup of temporary files

## Progress Tracking

The service now supports real-time progress tracking for bulk operations:

### How it works:
1. **Start Processing**: Send files to `/extract-progress` endpoint
2. **Get Session ID**: Receive a unique session ID for tracking
3. **Monitor Progress**: Poll `/progress/{session_id}` for real-time updates
4. **Clean Up**: Use `/progress/{session_id}` DELETE to clean up completed sessions

### Progress Response Format:
```json
{
  "session_id": "uuid-string",
  "status": "processing|completed|failed",
  "progress": 75.5,
  "total_files": 4,
  "processed_files": 3,
  "current_file": "document.pdf",
  "results": [...],
  "errors": [...],
  "elapsed_time": 12.3,
  "start_time": "2025-01-20T10:30:00",
  "end_time": "2025-01-20T10:30:15"
}
```

## Supported File Types

- **PDF**: Uses pdfplumber (pdfminer under the hood)
- **Word**: Supports modern .docx files (not legacy .doc)

## Error Handling

- File size limits enforced
- Request timeout protection
- Per-file extraction timeouts
- Graceful error responses with detailed messages
- Automatic cleanup on errors

## Monitoring

- Health check endpoint: `/health`
- Structured logging for debugging
- Resource usage monitoring through Railway dashboard
